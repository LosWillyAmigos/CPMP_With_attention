{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\OneDrive\\Documentos\\Projects\\Repositorio\\V2\\CPMP_With_attention-dev-Slinking196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El volumen de la unidad C es Acer\n",
      " El nï¿½mero de serie del volumen es: 5066-51DF\n",
      "\n",
      " Directorio de c:\\Users\\thoma\\OneDrive\\Documentos\\Projects\\Repositorio\\V2\\CPMP_With_attention-dev-Slinking196\n",
      "\n",
      "07-10-2024  11:22    <DIR>          .\n",
      "07-10-2024  11:22    <DIR>          ..\n",
      "27-09-2024  17:29                67 .gitignore\n",
      "07-10-2024  11:22    <DIR>          attentional_cpmp\n",
      "27-09-2024  17:29            49.843 CPMP_with_attention.ipynb\n",
      "27-09-2024  17:29            57.719 Data_generator.ipynb\n",
      "27-09-2024  17:29               490 README.md\n",
      "27-09-2024  17:29               220 requirements.txt\n",
      "27-09-2024  17:29             1.116 setup.py\n",
      "07-10-2024  11:04    <DIR>          test\n",
      "               6 archivos        109.455 bytes\n",
      "               4 dirs  62.721.912.832 bytes libres\n"
     ]
    }
   ],
   "source": [
    "%cd ../../\n",
    "%ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': {'layers': [{'type': 'ModelCPMP', 'name': 'cpmp_source_layer', 'sub_layers': [{'type': 'Dense', 'name': 'dense_layer', 'config': {'units': 128, 'activation_dense': 'sigmoid', 'use_bias_dense': True, 'kernel_initializer_dense': 'glorot_uniform', 'bias_initializer_dense': 'zeros', 'kernel_regularizer_dense': 'L1L2', 'kernel_regularizer_dense_value': 0.01, 'bias_regularizer_dense': 'L1L2', 'bias_regularizer_dense_value': 0.01, 'activity_regularizer_dense': None, 'kernel_constraint_dense': None, 'bias_constraint_dense': None}}, {'type': 'StackAttention', 'name': 'stack_attention_layer', 'config': {'num_stacks': 7, 'H': 7}, 'sub_layers': [{'type': 'MultiHeadAttention', 'name': 'multihead_attention', 'config': {'num_heads': 5, 'dropout': 0.2, 'key_dim': 64, 'value_dim': 128, 'use_bias_multihead': True, 'output_shape': 128, 'attention_axes': None, 'kernel_initializer_multihead': 'glorot_uniform', 'bias_initializer_multihead': 'zeros', 'kernel_regularizer_multihead': 'L1L2', 'kernel_regularizer_multihead_value': 0.01, 'bias_regularizer_multihead': 'L1L2', 'bias_regularizer_multihead_value': 0.01, 'activity_regularizer_multihead': None, 'kernel_constraint_multihead': None, 'bias_constraint_multihead': None}}, {'type': 'LayerNormalization', 'name': 'layer_normalization', 'config': {'axis': -1, 'epsilon': 0.001, 'center': True, 'scale': True, 'beta_initializer': 'zeros', 'gamma_initializer': 'ones', 'beta_regularizer': 'L1L2', 'beta_regularizer_value': 0.01, 'gamma_regularizer': 'L1L2', 'gamma_regularizer_value': 0.01, 'beta_constraint': None, 'gamma_constraint': None}}, {'type': 'FeedForward', 'name': 'feed_forward_hide_layer', 'config': {'dim_input_hide': 128, 'dim_output_hide': 128, 'list_neurons_hide': [256, 128, 64, 128, 256], 'activation_feed_hide': 'sigmoid', 'use_bias_feed_hide': True, 'kernel_initializer_feed_hide': 'glorot_uniform', 'bias_initializer_feed_hide': 'zeros', 'kernel_regularizer_feed_hide': 'L1L2', 'kernel_regularizer_feed_value_hide': 0.01, 'bias_regularizer_feed_hide': 'L1L2', 'bias_regularizer_feed_value_hide': 0.01, 'activity_regularizer_feed_hide': None, 'kernel_constraint_feed_hide': None, 'bias_constraint_feed_hide': None, 'rate_hide': 1e-06, 'noise_shape_hide': None, 'seed_hide': None, 'n_dropout_hide': 1}}]}, {'type': 'FeedForward', 'name': 'feed_forward_layer', 'config': {'list_neurons_feed_output': [256, 128, 64, 32, 16], 'activation_output': 'sigmoid', 'use_bias_output': True, 'kernel_initializer_output': 'glorot_uniform', 'bias_initializer_output': 'zeros', 'kernel_regularizer_feed_output': 'L1L2', 'kernel_regularizer_feed_value_output': 0.01, 'bias_regularizer_feed_output': 'L1L2', 'bias_regularizer_feed_value_output': 0.01, 'activity_regularizer_feed_output': None, 'kernel_constraint_feed_output': None, 'bias_constraint_feed_output': None, 'rate_output': 0.3, 'noise_shape_output': None, 'seed_output': None, 'n_dropout_output': 2}}]}], 'compile': {'optimizer': 'Adam', 'loss': 'binary_crossentropy', 'metrics': ['mae', 'mse']}}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Abrir y cargar el archivo JSON\n",
    "with open('./attentional_cpmp/model/config/parameters.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Mostrar los datos cargados\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(config:dict):\n",
    "    return (config[\"compile\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][0][\"config\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][1][\"config\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][1][\"sub_layers\"][0][\"config\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][1][\"sub_layers\"][1][\"config\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][1][\"sub_layers\"][2][\"config\"] |\n",
    "            config[\"layers\"][0][\"sub_layers\"][2][\"config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_stacks': 7, 'H': 7}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"model\"][\"layers\"][0][\"sub_layers\"][1][\"config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_params(data[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'Adam',\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'metrics': ['mae', 'mse'],\n",
       " 'units': 128,\n",
       " 'activation_dense': 'sigmoid',\n",
       " 'use_bias_dense': True,\n",
       " 'kernel_initializer_dense': 'glorot_uniform',\n",
       " 'bias_initializer_dense': 'zeros',\n",
       " 'kernel_regularizer_dense': 'L1L2',\n",
       " 'kernel_regularizer_dense_value': 0.01,\n",
       " 'bias_regularizer_dense': 'L1L2',\n",
       " 'bias_regularizer_dense_value': 0.01,\n",
       " 'activity_regularizer_dense': None,\n",
       " 'kernel_constraint_dense': None,\n",
       " 'bias_constraint_dense': None,\n",
       " 'num_heads': 5,\n",
       " 'dropout': 0.2,\n",
       " 'key_dim': 64,\n",
       " 'value_dim': 128,\n",
       " 'use_bias_multihead': True,\n",
       " 'output_shape': 128,\n",
       " 'attention_axes': None,\n",
       " 'kernel_initializer_multihead': 'glorot_uniform',\n",
       " 'bias_initializer_multihead': 'zeros',\n",
       " 'kernel_regularizer_multihead': 'L1L2',\n",
       " 'kernel_regularizer_multihead_value': 0.01,\n",
       " 'bias_regularizer_multihead': 'L1L2',\n",
       " 'bias_regularizer_multihead_value': 0.01,\n",
       " 'activity_regularizer_multihead': None,\n",
       " 'kernel_constraint_multihead': None,\n",
       " 'bias_constraint_multihead': None,\n",
       " 'axis': -1,\n",
       " 'epsilon': 0.001,\n",
       " 'center': True,\n",
       " 'scale': True,\n",
       " 'beta_initializer': 'zeros',\n",
       " 'gamma_initializer': 'ones',\n",
       " 'beta_regularizer': 'L1L2',\n",
       " 'beta_regularizer_value': 0.01,\n",
       " 'gamma_regularizer': 'L1L2',\n",
       " 'gamma_regularizer_value': 0.01,\n",
       " 'beta_constraint': None,\n",
       " 'gamma_constraint': None,\n",
       " 'dim_input_hide': 128,\n",
       " 'dim_output_hide': 128,\n",
       " 'list_neurons_hide': [256, 128, 64, 128, 256],\n",
       " 'activation_feed_hide': 'sigmoid',\n",
       " 'use_bias_feed_hide': True,\n",
       " 'kernel_initializer_feed_hide': 'glorot_uniform',\n",
       " 'bias_initializer_feed_hide': 'zeros',\n",
       " 'kernel_regularizer_feed_hide': 'L1L2',\n",
       " 'kernel_regularizer_feed_value_hide': 0.01,\n",
       " 'bias_regularizer_feed_hide': 'L1L2',\n",
       " 'bias_regularizer_feed_value_hide': 0.01,\n",
       " 'activity_regularizer_feed_hide': None,\n",
       " 'kernel_constraint_feed_hide': None,\n",
       " 'bias_constraint_feed_hide': None,\n",
       " 'rate_hide': 1e-06,\n",
       " 'noise_shape_hide': None,\n",
       " 'seed_hide': None,\n",
       " 'n_dropout_hide': 1,\n",
       " 'list_neurons_feed_output': [256, 128, 64, 32, 16],\n",
       " 'activation_output': 'sigmoid',\n",
       " 'use_bias_output': True,\n",
       " 'kernel_initializer_output': 'glorot_uniform',\n",
       " 'bias_initializer_output': 'zeros',\n",
       " 'kernel_regularizer_feed_output': 'L1L2',\n",
       " 'kernel_regularizer_feed_value_output': 0.01,\n",
       " 'bias_regularizer_feed_output': 'L1L2',\n",
       " 'bias_regularizer_feed_value_output': 0.01,\n",
       " 'activity_regularizer_feed_output': None,\n",
       " 'kernel_constraint_feed_output': None,\n",
       " 'bias_constraint_feed_output': None,\n",
       " 'rate_output': 0.3,\n",
       " 'noise_shape_output': None,\n",
       " 'seed_output': None,\n",
       " 'n_dropout_output': 2}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attentional_cpmp.model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thoma\\OneDrive\\Documentos\\Projects\\Repositorio\\V2\\CPMP_With_attention-dev-Slinking196\\attentional_cpmp\\model\\functions.py:101\u001b[0m, in \u001b[0;36mcreate_model\u001b[1;34m(H, num_stacks, num_heads, activation_dense, use_bias_dense, kernel_initializer_dense, bias_initializer_dense, kernel_regularizer_dense, kernel_regularizer_dense_value, bias_regularizer_dense, bias_regularizer_dense_value, activity_regularizer_dense, kernel_constraint_dense, bias_constraint_dense, dropout, key_dim, value_dim, use_bias_multihead, output_shape, attention_axes, kernel_initializer_multihead, bias_initializer_multihead, kernel_regularizer_multihead, kernel_regularizer_multihead_value, bias_regularizer_multihead, bias_regularizer_multihead_value, activity_regularizer_multihead, kernel_constraint_multihead, bias_constraint_multihead, dim_input_hide, dim_output_hide, list_neurons_hide, activation_feed_hide, use_bias_feed_hide, kernel_initializer_feed_hide, bias_initializer_feed_hide, kernel_regularizer_feed_hide, kernel_regularizer_feed_value_hide, bias_regularizer_feed_hide, bias_regularizer_feed_value_hide, activity_regularizer_feed_hide, kernel_constraint_feed_hide, bias_constraint_feed_hide, rate_hide, noise_shape_hide, seed_hide, n_dropout_hide, axis, epsilon, center, scale, beta_initializer, gamma_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, activation_output, list_neurons_feed_output, use_bias_output, kernel_initializer_output, bias_initializer_output, kernel_regularizer_feed_output, kernel_regularizer_feed_value_output, bias_regularizer_feed_output, bias_regularizer_feed_value_output, activity_regularizer_feed_output, kernel_constraint_feed_output, bias_constraint_feed_output, rate_output, noise_shape_output, seed_output, n_dropout_output, optimizer, loss, metrics, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_model\u001b[39m(H: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     24\u001b[0m                   num_stacks: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     25\u001b[0m                   num_heads: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m                   metrics: Any \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     99\u001b[0m                   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Model:\n\u001b[1;32m--> 101\u001b[0m     input_layer \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[43mH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m))\n\u001b[0;32m    103\u001b[0m     layer_attention_so \u001b[38;5;241m=\u001b[39m ModelCPMP(H\u001b[38;5;241m=\u001b[39mH, num_heads\u001b[38;5;241m=\u001b[39mnum_heads,\n\u001b[0;32m    104\u001b[0m                                    num_stacks\u001b[38;5;241m=\u001b[39mnum_stacks,\n\u001b[0;32m    105\u001b[0m                                    activation_dense\u001b[38;5;241m=\u001b[39mactivation_dense,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    174\u001b[0m                                    n_dropout_output\u001b[38;5;241m=\u001b[39mn_dropout_output,\n\u001b[0;32m    175\u001b[0m                                    \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)(input_layer)\n\u001b[0;32m    177\u001b[0m     expand \u001b[38;5;241m=\u001b[39m ExpandOutput()(layer_attention_so)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'NoneType' and 'int'"
     ]
    }
   ],
   "source": [
    "model = create_model(**config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
