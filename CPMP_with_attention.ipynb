{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZguIsxpfSMW5"
   },
   "source": [
    "## Librerias Necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "yNiC2hTiRXP1"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import CPMP_attention_model as cpmp_att"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlhLwF-Q0QXn"
   },
   "source": [
    "## Funciones para entrenamiento y predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "E30QJOw9P2si"
   },
   "outputs": [],
   "source": [
    "#************ | expand_dims_cpmp() | **************#\n",
    "# El proposito de esta función es expandir las     #\n",
    "# dimensiones de un estado menor para que pueda    #\n",
    "# ser predicho un por modelo para un estado mayor. #\n",
    "#                                                  #\n",
    "# Input:                                           #\n",
    "#     - data: Lista de matrices con todos los      #\n",
    "#             estados.                             #\n",
    "#     - labels: lista de posibles stacks de origen #\n",
    "#               o destino.                         #\n",
    "#     - stacks: Cantidad de stacks permitidos por  #    \n",
    "#               el modelo.                         #\n",
    "#     - height: Altura máxima de los stacks        #\n",
    "#               permitidos por el modelo.          #\n",
    "#                                                  #\n",
    "# Output:                                          #\n",
    "#      Retona un arreglo de los datos              #\n",
    "#      redimensionados con sus respectivos labels. #\n",
    "def expand_dims_cpmp(data, labels, stacks, height):\n",
    "    size = data.shape[1]\n",
    "    tuple_data = zip(data, labels)\n",
    "    data_2 = []\n",
    "    labels_2 = []\n",
    "\n",
    "    for matrix, label in tuple_data:\n",
    "        matrix = matrix.tolist()\n",
    "        label = label.tolist()\n",
    "        for i in range(stacks - size):\n",
    "            matrix.append([1] + [1 for n in range(height)])\n",
    "            label.append(0)\n",
    "\n",
    "        data_2.append(matrix)\n",
    "        labels_2.append(label)\n",
    "\n",
    "    return np.array(data_2), np.array(labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E-LnNyVzXc3e"
   },
   "outputs": [],
   "source": [
    "#*************** | concatenate_state_with_output() | ****************#\n",
    "# El proposito de esta función es concatenar la data de las estados  #\n",
    "# del problema con sus respectivos labels que indican el stack de    #\n",
    "# origen.                                                            #\n",
    "#                                                                    #\n",
    "# Input:                                                             #\n",
    "#     - states: Lista de matrices indicando los diversos estados.    #\n",
    "#     - outputs: Lista de stacks de origen.                          #\n",
    "#                                                                    #\n",
    "# Output:                                                            # \n",
    "#      Retorna un arreglo con los datos concatenados.                #\n",
    "def concatenate_state_with_output(states, outputs):\n",
    "    size_stacks = len(states[0])\n",
    "    size_height = len(states[0][0])\n",
    "    tuple_data = zip(states, outputs)\n",
    "    new_data = []\n",
    "\n",
    "    for state, output in tuple_data:\n",
    "        new_data.append([])\n",
    "\n",
    "        for i in range(size_stacks):\n",
    "            stack = state[i].tolist()\n",
    "            stack.append(output[i])\n",
    "            new_data[len(new_data) - 1].append(stack)\n",
    "\n",
    "    return np.stack(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************* | is_equal() | **************#\n",
    "# El proposito de esta función es verificar #\n",
    "# si los datos ingresados en dos arreglos   #\n",
    "# son exactamente iguales independiente de  #\n",
    "# su posición.                              #\n",
    "#                                           #\n",
    "# Input:                                    #\n",
    "#     - array1: Primer arreglo que se       #\n",
    "#               desea comparar.             #\n",
    "#     - array2: Segundo arreglo que se      #\n",
    "#               desea comparar.             #\n",
    "# Output:                                   #\n",
    "#     Retorna true en el caso de tener      #\n",
    "#     cada dato exactamente igual o         #\n",
    "#     False en caso contrario.              #\n",
    "def is_equal(array1, array2):\n",
    "    size = len(array1)\n",
    "    cant = 0\n",
    "    array1.sort()\n",
    "    array2.sort()\n",
    "\n",
    "    for i in range(size):\n",
    "        if array1[i] == array2[i]:\n",
    "            cant += 1\n",
    "\n",
    "    if cant == size: return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************** | precision() | ***************#\n",
    "# El proposito de esta función es verificar si    #\n",
    "# los valores predichos por una red neuronal son  #\n",
    "# correctos o no.                                 #\n",
    "#                                                 #\n",
    "# Input:                                          #\n",
    "#     - y_predict: Valores predichos por el       #\n",
    "#                  mecanismo de machine learning. #\n",
    "#     - y_test: Valores reales de los casos       #\n",
    "#               predichos.                        #\n",
    "# Output:                                         #\n",
    "#     Retorna una proporción entre los valores    #\n",
    "#     predichos correctamente sobre la cantidad   #\n",
    "#     de datos.                                   #\n",
    "def precision(y_predict, y_test):\n",
    "    size = len(y_predict)\n",
    "    predict = 0\n",
    "\n",
    "    for i in range(size):\n",
    "        if np.argmax(y_predict[i]) == np.argmax(y_test[i]):\n",
    "            predict += 1\n",
    "    \n",
    "    return predict / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************** | precision_for_multiclass() | ***************#\n",
    "# El proposito de esta función es verificar si los valores    #\n",
    "# predichos por un mecanismo de machine learning para         #\n",
    "# clasificación multiclase están correctos o no.              #\n",
    "#                                                             # \n",
    "# Input:                                                      #\n",
    "#     - y_predict: Valores predichos por el mecanismo de      #\n",
    "#                  machine learning.                          #\n",
    "#     - y_test: Valores reales de cada caso.                  #\n",
    "# Output:                                                     #\n",
    "#     Retorna una proporción entre los valores predichos      #\n",
    "#     correctamente sobre la cantidad total de casos.         #\n",
    "def precision_for_multiclass(y_predict, y_test):\n",
    "    size = len(y_predict)\n",
    "    predict = 0\n",
    "\n",
    "    for i in range(size):\n",
    "        cant_sol = np.count_nonzero(y_test[i] == 1.)\n",
    "        \n",
    "        indices_test = np.argsort(y_test[i])\n",
    "        indices_test = indices_test[-cant_sol:]\n",
    "        indices_predict = np.argsort(y_predict[i])\n",
    "        indices_predict = indices_predict[-cant_sol:]\n",
    "\n",
    "        if is_equal(indices_test, indices_predict):\n",
    "            predict += 1\n",
    "    \n",
    "    return predict / size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aP6a1L690e9A"
   },
   "source": [
    "## Funciones para cargar y guardar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ooF3wmbGkcx3"
   },
   "outputs": [],
   "source": [
    "#************** | load_data() | ************#\n",
    "# El proposito de esta función es cargar    #\n",
    "# los datos almacenados en un csv para el   #\n",
    "# entrenamiento de la red neuronal.         #\n",
    "#                                           #\n",
    "# Input:                                    #\n",
    "#     - name: Nombre del archivo con su     #\n",
    "#             dirección correspondiente     #\n",
    "#             sin el .csv.                  #\n",
    "#                                           #\n",
    "# Output:                                   #\n",
    "#      Retorna 3 arreglos, el primero       #\n",
    "#      corresponde a una lista de estados,  #\n",
    "#      el segundo a una lista de labels     #\n",
    "#      de stacks de origen y por último una #\n",
    "#      lista de posibles stacks de destino. #\n",
    "def load_data(name):\n",
    "    data = []\n",
    "    labels_1 = []\n",
    "    labels_2 = []\n",
    "\n",
    "    with open(name + '.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_1 = archivo.readline().split(':')[1].split(',')\n",
    "            label_1 = np.array(label_1, dtype= float)\n",
    "            label_2 = archivo.readline().split(':')[1].split(',')\n",
    "            label_2 = np.array(label_2, dtype= float)\n",
    "\n",
    "            data.append(matrix)\n",
    "            labels_1.append(label_1)\n",
    "            labels_2.append(label_2)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    return np.stack(data), np.stack(labels_1), np.stack(labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data_multi(name):\n",
    "    data = []\n",
    "    data_2 = []\n",
    "    labels_1 = []\n",
    "    labels_2 = []\n",
    "\n",
    "    with open(name + '_so.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_1 = archivo.readline().split(':')[1].split(',')\n",
    "            label_1 = np.array(label_1, dtype= float)\n",
    "\n",
    "            data.append(matrix)\n",
    "            labels_1.append(label_1)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    with open(name + '_sd.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_2 = archivo.readline().split(':')[1].split(',')\n",
    "            label_2 = np.array(label_2, dtype= float)\n",
    "\n",
    "            data_2.append(matrix)\n",
    "            labels_2.append(label_2)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    return np.stack(data), np.stack(data_2), np.stack(labels_1), np.stack(labels_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "s6iA7ua21Rg-"
   },
   "outputs": [],
   "source": [
    "data_7x7, labels_1_7x7, labels_2_7x7 = load_data('data/data_7x7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5x5, labels_1_5x5, labels_2_5x5 = load_data('data/data_5x5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5x5_multi, labels_1_5x5_multi, labels_2_5x5_multi = load_data('data/data_5x5_SO_Multiple_alpha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0d_OVs1CTak"
   },
   "source": [
    "# Modelo con Varias Salidas"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
