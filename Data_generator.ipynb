{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\Mi unidad\\PUCV\\CPMP_With_attetion\\CPMP-ML\n"
     ]
    }
   ],
   "source": [
    "%cd CPMP-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import cpmp_ml\n",
    "from cpmp_ml import generate_random_layout\n",
    "from cpmp_ml import generate_data, get_move, generate_data2\n",
    "from copy import deepcopy\n",
    "import CPMP_attention_model as cpmp_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:\\Mi unidad\\PUCV\\CPMP_With_attetion\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo Greedy y funciones para generación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************* | Función is_valid_BG_move() | ****************#\n",
    "# El proposito de esta función es validar si el movimiento    #\n",
    "# dentro del estado actual del problema actual al que se le   #\n",
    "# desea realizar sirve para resolver el problema o no.        #  \n",
    "#                                                             #\n",
    "# Input:                                                      #\n",
    "#     - layout: Variable que contiene el estado al que se     #\n",
    "#               le desea realizar el movimiento.              #\n",
    "#     - s_o: Stack de origen                                  #\n",
    "#     - S_d: Stack de destino                                 #\n",
    "#                                                             #\n",
    "# Output:                                                     #\n",
    "#     La función retorna True en caso de ser un movimiento    #\n",
    "#     posible o False en caso contrario.                      #\n",
    "def is_valid_BG_move(layout: cpmp_ml.Layout, s_o: int, s_d: int) -> bool:\n",
    "    if (s_o != s_d  and len(layout.stacks[s_o]) > 0\n",
    "    and  len(layout.stacks[s_d]) < layout.H\n",
    "    and layout.is_sorted_stack(s_o)==False\n",
    "    and layout.is_sorted_stack(s_d)==True\n",
    "    and layout.gvalue(s_o) <= layout.gvalue(s_d)):\n",
    "      return True\n",
    "\n",
    "    else: return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********** | Función select_bg_move() | ************#\n",
    "# El proposito de esta función es seleccionar un      #\n",
    "# movimiento que optimice la diferencia entre las     #\n",
    "# prioridades entre los contenedores del stack de     #\n",
    "# destino y el stack de origen.                       #\n",
    "#                                                     #\n",
    "# Input:                                              #\n",
    "#     - layout: Variable que contiene el estado       #\n",
    "#               actual al que se le desea realizar    #\n",
    "#               el movimiento.                        #\n",
    "#                                                     #\n",
    "# Output:                                             #\n",
    "#   Retorna una tupla indicando el stack de origen    #\n",
    "#   y el stack de destino que minimiza la             #\n",
    "#   diferencia antes mencionada o en caso contrario   #\n",
    "#   retorna None.                                     #\n",
    "def select_bg_move(layout: cpmp_ml.Layout) -> tuple:\n",
    "  bg_move = None # Tupla de movimiento optimo\n",
    "  S=len(layout.stacks) # Cantidad de stacks\n",
    "  min_diff = 100\n",
    "  for s_o in range(S):\n",
    "     for s_d in range(S):\n",
    "       if is_valid_BG_move(layout, s_o, s_d):\n",
    "          diff = layout.gvalue(s_d) - layout.gvalue(s_o)\n",
    "          if min_diff > diff:\n",
    "            min_diff = diff\n",
    "            bg_move = (s_o,s_d)\n",
    "  return bg_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************* | Función greedy | **************#\n",
    "# El proposito de esta función es utilizar un   #\n",
    "# algoritmo greedy para resolver el problema    #\n",
    "# CPMP.                                         #\n",
    "#                                               #\n",
    "# Input:                                        #\n",
    "#     - layout: El estado al cual se le desea   #\n",
    "#               aplicar el algoritmo greedy     #\n",
    "#               para resolverlo.                #\n",
    "# Output:                                       #\n",
    "#     La función retorna la cantidad de         #\n",
    "#     movimientos que toma resolver el problema #\n",
    "#     con el algoritmo y los movimientos que    #\n",
    "#     debe llevar a cabo, en caso de no poder   #\n",
    "#     ser resuelto retorna como cantidad de     #\n",
    "#     pasos -1 y None en movimientos.           #\n",
    "def greedy(layout: cpmp_ml.Layout) -> tuple:\n",
    "    moves = []\n",
    "    steps = 0\n",
    "    while layout.unsorted_stacks>0:\n",
    "        bg_move=select_bg_move(layout)\n",
    "        if bg_move is not None:\n",
    "            moves.append(bg_move)\n",
    "            layout.move(bg_move)\n",
    "        else:\n",
    "            return -1, None # no lo resuelve\n",
    "        steps +=1\n",
    "\n",
    "    if layout.unsorted_stacks==0:\n",
    "        return steps, moves\n",
    "    return -1, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**************** | Función unlist() | ***************#\n",
    "# El proposito de esta función es unificar las        #\n",
    "# diversas listas de datos con los nuevos datos a     #\n",
    "# ingresar.                                           #\n",
    "#                                                     #\n",
    "# Input:                                              #\n",
    "#     - data: Lista de matrices principal.            #\n",
    "#     - labels1: Lista de stacks de origen principal. #\n",
    "#     - labels2: Lista de stacks de destino principal.#\n",
    "#     - state: Lista de matrices con nuevos datos.    #\n",
    "#     - source: Lista de stacks de origen con nuevos  #\n",
    "#               datos.                                #\n",
    "#     - destination: Lista de stacks de destino con   #\n",
    "#                    nuevos datos.                    #\n",
    "#                                                     #\n",
    "# Output:                                             #\n",
    "#     No retorna valores.                             #\n",
    "def unlist(data: list, labels1: list, labels2: list, \n",
    "           state: list, source: list, destination: list\n",
    "           ) -> None:\n",
    "  n = len(source) # Cantidad de datos nuevos\n",
    "  for i in range(n):\n",
    "    data.append(state[i])\n",
    "    labels1.append(source[i])\n",
    "    labels2.append(destination[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************* | get_ann_state() | **************#\n",
    "# El proposito de esta función preparar los      #\n",
    "# datos de un estado del problema CPMP para que  #\n",
    "# pueda ser leído por una red neuronal.          #\n",
    "#                                                #\n",
    "# Input:                                         #\n",
    "#     - layout: Estado actual del problema CPMP. #\n",
    "#                                                #\n",
    "# Output:                                        #\n",
    "#     Retorna una matriz con los datos           #\n",
    "#     normalizados.                              #\n",
    "def get_ann_state(layout: cpmp_ml.Layout) -> np.ndarray:\n",
    "  S=len(layout.stacks) # Cantidad de stacks\n",
    "  #matriz de stacks\n",
    "  b = 2. * np.ones([S,layout.H + 1]) # Matriz normalizada\n",
    "  for i,j in enumerate(layout.stacks):\n",
    "     b[i][layout.H-len(j) + 1:] = [k/layout.total_elements for k in j]\n",
    "     b[i][0] = layout.is_sorted_stack(i)\n",
    "  b.shape=(S,(layout.H + 1))\n",
    "  return b\n",
    "\n",
    "#overriding the function in the module\n",
    "cpmp_ml.get_ann_state = get_ann_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************ | convert_label() | ************#\n",
    "# El proposito de esta función es convertir   #  \n",
    "# una matriz en una lista con los datos       #\n",
    "# apilados de forma que una red neuronal los  #\n",
    "# use como etiquetas.                         #\n",
    "#                                             #\n",
    "# Input:                                      #\n",
    "#     - score: Una matriz con datos binarios. #\n",
    "#                                             #\n",
    "# Output:                                     #\n",
    "#      Retorna una lista con los datos de la  #\n",
    "#      matriz apilados.                       #      \n",
    "def convert_label(score: np.ndarray) -> np.ndarray:\n",
    "    list_score = []\n",
    "\n",
    "    for i in score:\n",
    "        list_score.append(i)\n",
    "\n",
    "    return np.array(list_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************ | generate_steps_of_a_state() | *****************#\n",
    "# El proposito de esta función es generar todos los            #\n",
    "# movimientos que resuelven un estado a través de un algorimo  #\n",
    "# greedy.                                                      #\n",
    "#                                                              #\n",
    "# Input:                                                       #\n",
    "#     - layout: El estado actual que se desea resolver.        #\n",
    "#                                                              #\n",
    "# Output:                                                      #\n",
    "#      - states: Lista de todos los estados de la solución.    #\n",
    "#      - source_tags: Lista de todos los stacks de origen.     #\n",
    "#      - destination_tags: Lista de todos los stacks de        #\n",
    "#                          destino.                            #\n",
    "#       En caso de no poder resolver el estado actual,         #\n",
    "#       cada una de las variables antes mencionadas retorna    #\n",
    "#       None.                                                  #\n",
    "def generate_steps_of_a_state(layout: cpmp_ml.Layout) -> tuple:\n",
    "    states = [] # estados antes de movimiento\n",
    "    source_tags = [] # etiquetas origen\n",
    "    destination_tags = []  # etiquetas destino\n",
    "\n",
    "    aux = deepcopy(layout)  # creación de copia de objeto\n",
    "\n",
    "    steps, moves = greedy(aux)\n",
    "    if steps == -1:\n",
    "      return None, None, None\n",
    "\n",
    "    for i in range(steps):\n",
    "        states.append(get_ann_state(layout)) # antes del movimiento\n",
    "        source_tags.append(convert_label(to_categorical(moves[i][0],len(layout.stacks))))\n",
    "        destination_tags.append(convert_label(to_categorical(moves[i][1],len(layout.stacks))))\n",
    "        layout.move(moves[i])\n",
    "        aux = deepcopy(layout)\n",
    "\n",
    "    return states, source_tags, destination_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************** | create_different_states() | ***************#\n",
    "# El proposito de esta función es crear diferentes            #\n",
    "# estados para el problema CPMP con sus respectivas           #\n",
    "# soluciones calculadas con un algoritmo greedy.              #\n",
    "#                                                             #\n",
    "# Input:                                                      #\n",
    "#     - S: Cantidad de stacks.                                #\n",
    "#     - H: Altura de los stacks                               #\n",
    "#     - max_priority_container: la prioridad máxima de        #\n",
    "#                               los contenedores y a la       #\n",
    "#                               vez el total de contenedores. #\n",
    "#     - n: cantidad de nuevos estados.                        #\n",
    "# Output:                                                     #\n",
    "#     Retorna arreglos que representan los distintos          #\n",
    "#     estados con otros dos arreglos que contienen sus        #\n",
    "#     posibles stacks de origen y de destino.                 #\n",
    "def create_different_states(S: int, H: int, \n",
    "                            max_priority_container: int, n: int\n",
    "                            ) -> tuple:\n",
    "  data_state = []\n",
    "  labels_source = []\n",
    "  labels_destination = []\n",
    "  iter = 0\n",
    "  while iter < n:\n",
    "    layout = generate_random_layout(S,H,max_priority_container)\n",
    "    state, source, destination = generate_steps_of_a_state(layout)\n",
    "    if state == None and source == None and destination == None: continue\n",
    "    unlist(data_state,labels_source,labels_destination,state,source,destination)\n",
    "    iter+=1\n",
    "\n",
    "  return np.stack(data_state), np.stack(labels_source), np.stack(labels_destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************** | concatenate_state_with_output() | ****************#\n",
    "# El proposito de esta función es concatenar la data de las estados  #\n",
    "# del problema con sus respectivos labels que indican el stack de    #\n",
    "# origen.                                                            #\n",
    "#                                                                    #\n",
    "# Input:                                                             #\n",
    "#     - states: Lista de matrices indicando los diversos estados.    #\n",
    "#     - outputs: Lista de stacks de origen.                          #\n",
    "#                                                                    #\n",
    "# Output:                                                            # \n",
    "#      Retorna un arreglo con los datos concatenados.                #\n",
    "def concatenate_states_with_outputs(states: list, outputs: list) -> np.ndarray:\n",
    "    size_stacks = len(states[0])\n",
    "    size_height = len(states[0][0])\n",
    "    tuple_data = zip(states, outputs)\n",
    "    new_data = []\n",
    "\n",
    "    for state, output in tuple_data:\n",
    "        new_data.append([])\n",
    "\n",
    "        for i in range(size_stacks):\n",
    "            stack = state[i].tolist()\n",
    "            stack.append(output[i])\n",
    "            new_data[len(new_data) - 1].append(stack)\n",
    "\n",
    "    return np.stack(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*************** | concatenate_state_with_output() | ******************#\n",
    "# El proposito de esta función es concatenar un estado con los         #\n",
    "# posibles stacks de origen.                                           #\n",
    "#                                                                      #\n",
    "# Input:                                                               #\n",
    "#     - state: Arreglo que contiene un estado del problema.            #\n",
    "#     - output: Arreglo que contiene los posibles stacks de origen.    #\n",
    "#     - S: Cantidad de stacks.                                         #\n",
    "# Output:                                                              #\n",
    "#     Retorna el estado concatenado.                                   #\n",
    "def concatenate_state_with_output(state: np.ndarray, \n",
    "                                  output: np.ndarray, S: int\n",
    "                                  ) -> np.ndarray:\n",
    "    state_aux = deepcopy(state)\n",
    "    new_state = []\n",
    "    for i in range(S):\n",
    "        stack = state_aux[i].tolist()\n",
    "        stack.append(output[i])\n",
    "        new_state.append(stack)\n",
    "\n",
    "    return np.stack(new_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************* | get_so_sd_train() | **************#\n",
    "# El proposito de esta función es obtener los      #\n",
    "# stacks de origen y destino de un estado n x m.   #\n",
    "#                                                  #\n",
    "# Input:                                           #\n",
    "#     - data: Lista de estados                     #\n",
    "#     - labels: Lista de stacks descritos en un    #\n",
    "#               arreglo de largo n * m.            #\n",
    "#     - S: Cantidad de stacks                      #\n",
    "#     - H: Altura de los estados                   #\n",
    "#     - verbose: variable para activar el          #\n",
    "#                seguimiento de la función.        #\n",
    "def get_so_sd_train(data: list, labels: list, \n",
    "                    S: int = 5, H: int = 5, \n",
    "                    verbose: bool = False) -> tuple:\n",
    "  so_train = []\n",
    "  sd_train = []\n",
    "  i = 0\n",
    "  data_2 = []\n",
    "  size = len(labels)\n",
    "\n",
    "  for i in range(size):\n",
    "    so = np.zeros(S)\n",
    "    k=0\n",
    "    size_2 = len(labels[i])\n",
    "    flag = False\n",
    "    for j in range(size_2):\n",
    "      if labels[i][j] == 1.0:\n",
    "        move = get_move(k,S,H)\n",
    "\n",
    "        if not flag:\n",
    "          aux = move[0]\n",
    "          sd = np.zeros(S)\n",
    "          so_aux = np.zeros(S)\n",
    "          so_aux[aux] = 1.\n",
    "          data_2.append(concatenate_state_with_output(data[i], so_aux, S))\n",
    "          sd[move[1]] = 1.\n",
    "          flag = True\n",
    "        elif aux != move[0]:\n",
    "          aux = move[0]\n",
    "          sd_train.append(sd)\n",
    "          so_aux = np.zeros(S)\n",
    "          sd = np.zeros(S)\n",
    "          so_aux[aux] = 1.\n",
    "          data_2.append(concatenate_state_with_output(data[i], so_aux, S))\n",
    "          sd[move[1]] = 1.\n",
    "        else:\n",
    "          sd[move[1]] = 1.\n",
    "\n",
    "        if verbose: print(\"optimal_move:\", move)\n",
    "\n",
    "        so[move[0]]= 1.0\n",
    "\n",
    "      k+=1\n",
    "    if verbose: print(\"\")\n",
    "    sd_train.append(sd)\n",
    "    so_train.append(so)\n",
    "    i += 1\n",
    "\n",
    "  \n",
    "  return np.array(data_2), np.array(so_train), np.array(sd_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones para guardar y generar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#***************** | save_data() | *****************#\n",
    "# El proposito de esta función es almacenar datos   #\n",
    "# de entrenamiento en un archivo csv.               #\n",
    "#                                                   #\n",
    "# Input:                                            #\n",
    "#     - data: Lista de matrices con los estados     #\n",
    "#             correspondientes.                     #\n",
    "#     - labels_1: Lista con los posibles stacks de  #   \n",
    "#                 origen.                           #\n",
    "#     - labels_2: Lista con los posibles stacks de  #\n",
    "#                 destino.                          #\n",
    "#     - name: Dirección y/o nombre del archivo      #\n",
    "#             sin el .csv.                          #\n",
    "# Output:                                           #\n",
    "#      No retorna valores.                          #\n",
    "def save_data(data: list, labels_1: list, labels_2: list, name: str) -> None:\n",
    "    size_stack = len(data[0])\n",
    "    size_height = len(data[0][0])\n",
    "    total_data = len(data)\n",
    "    tuple_data = zip(data, labels_1, labels_2)\n",
    "\n",
    "    with open(name + '.csv', 'w') as archivo:\n",
    "        archivo.write('Total data: ' + str(total_data) + '\\n')\n",
    "        archivo.write('Stacks:' + str(size_stack) + ',Height:' + str(size_height) + '\\n')\n",
    "        archivo.write('\\n')\n",
    "\n",
    "        for matrix, label_1, label_2 in tuple_data:\n",
    "            lista_stack = matrix.flatten()\n",
    "            archivo.write('matrix:' + str(lista_stack.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('label_1:' + str(label_1.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('label_2:' + str(label_2.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('\\n')\n",
    "\n",
    "        archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2(name: str) -> tuple:\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    with open(name + '.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_1 = archivo.readline().split(':')[1].split(',')\n",
    "            label_1 = np.array(label_1, dtype= float)\n",
    "\n",
    "            data.append(matrix)\n",
    "            labels.append(label_1)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    return np.stack(data), np.stack(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************** | load_data() | ************#\n",
    "# El proposito de esta función es cargar    #\n",
    "# los datos almacenados en un csv para el   #\n",
    "# entrenamiento de la red neuronal.         #\n",
    "#                                           #\n",
    "# Input:                                    #\n",
    "#     - name: Nombre del archivo con su     #\n",
    "#             dirección correspondiente     #\n",
    "#             sin el .csv.                  #\n",
    "#                                           #\n",
    "# Output:                                   #\n",
    "#      Retorna 3 arreglos, el primero       #\n",
    "#      corresponde a una lista de estados,  #\n",
    "#      el segundo a una lista de labels     #\n",
    "#      de stacks de origen y por último una #\n",
    "#      lista de posibles stacks de destino. #\n",
    "def load_data(name: str) -> tuple:\n",
    "    data = []\n",
    "    labels_1 = []\n",
    "    labels_2 = []\n",
    "\n",
    "    with open(name + '.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_1 = archivo.readline().split(':')[1].split(',')\n",
    "            label_1 = np.array(label_1, dtype= float)\n",
    "            label_2 = archivo.readline().split(':')[1].split(',')\n",
    "            label_2 = np.array(label_2, dtype= float)\n",
    "\n",
    "            data.append(matrix)\n",
    "            labels_1.append(label_1)\n",
    "            labels_2.append(label_2)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    return np.stack(data), np.stack(labels_1), np.stack(labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********************* | save_data_multi | *********************#\n",
    "# El proposito de esta función es guardar la data creada        #\n",
    "# en un archivo csv para que pueda ser usada más adelante.      #\n",
    "#                                                               #\n",
    "# Input:                                                        #\n",
    "#     - data: Lista que contiene los estados sin repetición.    #\n",
    "#     - data_2: Lista que contiene los estados con posible      #\n",
    "#               repetición concatenados a sus stacks de origen. #\n",
    "#     - labels_1: Posibles stacks de origen                     #\n",
    "#     - labels_2: Posibles stacks de destino                    #\n",
    "#     - name: Nombre del archivo                                #\n",
    "# Output:                                                       #\n",
    "#     Esta función no retorna valores.                          #\n",
    "def save_data_multi(data: list, data_2: list, labels_1: list, labels_2: list, name: str) -> None:\n",
    "    size_stack = len(data[0])\n",
    "    size_height = len(data[0][0])\n",
    "    total_data_1 = len(data)\n",
    "    total_data_2 = len(data_2)\n",
    "    tuple_data_1 = zip(data, labels_1)\n",
    "    tuple_data_2 = zip(data_2, labels_2)\n",
    "\n",
    "    with open(name + '_so.csv', 'w') as archivo:\n",
    "        archivo.write('Total data: ' + str(total_data_1) + '\\n')\n",
    "        archivo.write('Stacks:' + str(size_stack) + ',Height:' + str(size_height) + '\\n')\n",
    "        archivo.write('\\n')\n",
    "\n",
    "        for matrix, label_1 in tuple_data_1:\n",
    "            lista_stack = matrix.flatten()\n",
    "            archivo.write('matrix_1:' + str(lista_stack.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('label_1:' + str(label_1.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('\\n')\n",
    "\n",
    "        archivo.close()\n",
    "\n",
    "    with open(name + '_sd.csv', 'w') as archivo:\n",
    "        archivo.write('Total data: ' + str(total_data_2) + '\\n')\n",
    "        archivo.write('Stacks:' + str(size_stack) + ',Height:' + str(size_height + 1) + '\\n')\n",
    "        archivo.write('\\n')\n",
    "\n",
    "        for matrix, label_2 in tuple_data_2:\n",
    "            lista_stack = matrix.flatten()\n",
    "            archivo.write('matrix_2:' + str(lista_stack.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('label_2:' + str(label_2.tolist())[1:-1] + '\\n')\n",
    "            archivo.write('\\n')\n",
    "\n",
    "        archivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#**************** | load_data_multi() | *****************#\n",
    "# El proposito de esta función es cargar la data         #\n",
    "# guardad localmente de un archivo csv.                  #\n",
    "#                                                        #\n",
    "# Input:                                                 #\n",
    "#     - name: Nombre del archivo                         #\n",
    "# Output:                                                #\n",
    "#     Esta función no retorna valores.                   # \n",
    "def load_data_multi(name: str) -> tuple:\n",
    "    data = []\n",
    "    data_2 = []\n",
    "    labels_1 = []\n",
    "    labels_2 = []\n",
    "\n",
    "    with open(name + '_so.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_1 = archivo.readline().split(':')[1].split(',')\n",
    "            label_1 = np.array(label_1, dtype= float)\n",
    "\n",
    "            data.append(matrix)\n",
    "            labels_1.append(label_1)\n",
    "\n",
    "            archivo.readline()\n",
    "    \n",
    "    with open(name + '_sd.csv', 'r') as archivo:\n",
    "        total = int(archivo.readline().split(':')[1])\n",
    "        line = archivo.readline().split(':')\n",
    "        size_stacks = int(line[1].split(',')[0])\n",
    "        size_height = int(line[2])\n",
    "        archivo.readline()\n",
    "\n",
    "        for i in range(total):\n",
    "            matrix = archivo.readline().split(':')[1].split(',')\n",
    "            matrix = np.array(matrix, dtype= float)\n",
    "            matrix = np.reshape(matrix, (size_stacks, size_height))\n",
    "\n",
    "            label_2 = archivo.readline().split(':')[1].split(',')\n",
    "            label_2 = np.array(label_2, dtype= float)\n",
    "\n",
    "            data_2.append(matrix)\n",
    "            labels_2.append(label_2)\n",
    "\n",
    "            archivo.readline()\n",
    "\n",
    "    return np.stack(data), np.stack(data_2), np.stack(labels_1), np.stack(labels_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de data para un solo stack de origen y destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de stacks\n",
    "S = 5#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Altura de la bahía\n",
    "H = 7#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Número máximo de prioridad\n",
    "MPC = 32 #@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Cantida casos de entrenamiento\n",
    "N = 10000 #@param {type:'slider',min:1,max:100000,steps:1}\n",
    "\n",
    "X_train, y_train_so, y_train_sd = create_different_states(S, H, MPC, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de stacks\n",
    "S2 = 3 #@param {type:'slider',min:1,max:100,steps:1}\n",
    "\n",
    "# Altura de la bahía\n",
    "H2 = 7 #@param {type:'slider',min:1,max:100,steps:1}\n",
    "\n",
    "# Número máximo de prioridad\n",
    "MPC2 = 12 #@param {type:'slider',min:1,max:100,steps:1}\n",
    "\n",
    "# Cantida casos de prueba\n",
    "N2 = 500 #@param {type:'slider',min:1,max:10000,steps:1}\n",
    "\n",
    "X_test, y_test_so, y_test_sd = create_different_states(S2, H2, MPC2, N2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de data para multiples stacks de origen y destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de stacks\n",
    "S = 10#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Altura de la bahía\n",
    "H = 10#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Número máximo de prioridad\n",
    "MPC = 62 #@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Cantida casos de entrenamiento\n",
    "N = 100000 #@param {type:'slider',min:1,max:100000,steps:1}\n",
    "\n",
    "data_so, labels = generate_data(S= S, H= H, N= MPC, sample_size= N, perms_by_layout= 1)\n",
    "data_sd, labels_so, labels_sd = get_so_sd_train(data_so, labels, S= S, H= H) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generador de data con modelo\n",
    "### Función que es necesaria cambiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_move_2(act, S=5,H=5):\n",
    "  k=0\n",
    "  for i in range(S):\n",
    "    for j in range(H):\n",
    "      if k==act: return (i,j)\n",
    "      k+=1\n",
    "\n",
    "cpmp_ml.get_move = get_move_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Model_CPMP.call of <Layers.Model_CPMP object at 0x000002E232ECAAD0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Model_CPMP.call of <Layers.Model_CPMP object at 0x000002E232ECAAD0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "model_5x5 = cpmp_att.CPMP_attention_model()\n",
    "model_5x5.set_model('models/model_cpmp_5x5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7x7 = cpmp_att.CPMP_attention_model()\n",
    "model_7x7.set_model('models/model_cpmp_7x7.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cantidad de stacks\n",
    "S = 5#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Altura de la bahía\n",
    "H = 5#@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Número máximo de prioridad\n",
    "MPC = 15 #@param {type:'slider',min:1,max:1000,steps:1}\n",
    "\n",
    "# Cantida casos de entrenamiento\n",
    "N = 15 #@param {type:'slider',min:1,max:100000,steps:1}\n",
    "\n",
    "data_so, labels = generate_data2(model= model_5x5, S= S, H= H, N= MPC, sample_size= N, batch_size=20, perms_by_layout= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1.        , 2.        , 2.        , 2.        , 0.86666667,\n",
       "         0.4       ],\n",
       "        [0.        , 2.        , 2.        , 0.2       , 0.26666667,\n",
       "         0.33333333],\n",
       "        [0.        , 2.        , 0.26666667, 0.46666667, 0.66666667,\n",
       "         0.8       ],\n",
       "        [1.        , 2.        , 2.        , 0.93333333, 0.66666667,\n",
       "         0.53333333],\n",
       "        [0.        , 2.        , 2.        , 0.4       , 0.33333333,\n",
       "         0.4       ]]),\n",
       " array([[1.        , 2.        , 2.        , 2.        , 0.73333333,\n",
       "         0.53333333],\n",
       "        [0.        , 0.13333333, 0.2       , 0.46666667, 0.2       ,\n",
       "         0.26666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         2.        ],\n",
       "        [0.        , 2.        , 2.        , 0.66666667, 0.2       ,\n",
       "         0.33333333],\n",
       "        [0.        , 1.        , 0.86666667, 0.53333333, 0.4       ,\n",
       "         0.73333333]]),\n",
       " array([[0.        , 2.        , 0.8       , 0.33333333, 0.46666667,\n",
       "         0.93333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.73333333,\n",
       "         0.73333333],\n",
       "        [0.        , 2.        , 0.86666667, 0.93333333, 0.93333333,\n",
       "         0.33333333],\n",
       "        [0.        , 2.        , 0.4       , 0.06666667, 0.26666667,\n",
       "         0.26666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.86666667]]),\n",
       " array([[0.        , 2.        , 2.        , 0.06666667, 0.13333333,\n",
       "         0.4       ],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.93333333],\n",
       "        [0.        , 2.        , 0.66666667, 0.46666667, 0.06666667,\n",
       "         0.4       ],\n",
       "        [0.        , 0.4       , 0.33333333, 0.46666667, 0.86666667,\n",
       "         0.46666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.93333333,\n",
       "         0.73333333]]),\n",
       " array([[0.        , 2.        , 2.        , 0.73333333, 0.6       ,\n",
       "         0.66666667],\n",
       "        [1.        , 2.        , 2.        , 1.        , 0.33333333,\n",
       "         0.06666667],\n",
       "        [0.        , 0.46666667, 0.06666667, 0.26666667, 0.86666667,\n",
       "         0.8       ],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.4       ,\n",
       "         0.33333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.86666667,\n",
       "         0.86666667]]),\n",
       " array([[1.        , 2.        , 2.        , 0.6       , 0.6       ,\n",
       "         0.4       ],\n",
       "        [0.        , 0.86666667, 0.33333333, 0.33333333, 0.8       ,\n",
       "         0.2       ],\n",
       "        [0.        , 2.        , 2.        , 0.86666667, 0.66666667,\n",
       "         0.73333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.86666667,\n",
       "         0.8       ],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.33333333,\n",
       "         0.26666667]]),\n",
       " array([[1.        , 2.        , 2.        , 0.73333333, 0.73333333,\n",
       "         0.73333333],\n",
       "        [1.        , 2.        , 2.        , 0.6       , 0.2       ,\n",
       "         0.06666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.13333333],\n",
       "        [0.        , 2.        , 0.53333333, 0.8       , 0.06666667,\n",
       "         0.06666667],\n",
       "        [0.        , 2.        , 0.13333333, 0.13333333, 0.66666667,\n",
       "         0.66666667]]),\n",
       " array([[0.        , 0.93333333, 0.06666667, 0.6       , 0.8       ,\n",
       "         0.33333333],\n",
       "        [0.        , 2.        , 2.        , 2.        , 0.2       ,\n",
       "         0.26666667],\n",
       "        [0.        , 2.        , 0.06666667, 0.66666667, 0.8       ,\n",
       "         0.4       ],\n",
       "        [0.        , 2.        , 0.66666667, 0.4       , 1.        ,\n",
       "         0.06666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         2.        ]]),\n",
       " array([[1.        , 2.        , 2.        , 2.        , 0.66666667,\n",
       "         0.26666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.73333333],\n",
       "        [0.        , 0.8       , 0.66666667, 0.73333333, 0.2       ,\n",
       "         0.86666667],\n",
       "        [0.        , 2.        , 2.        , 0.6       , 0.6       ,\n",
       "         0.93333333],\n",
       "        [0.        , 2.        , 0.26666667, 0.13333333, 0.4       ,\n",
       "         0.93333333]]),\n",
       " array([[0.        , 0.73333333, 0.8       , 0.13333333, 0.8       ,\n",
       "         0.73333333],\n",
       "        [0.        , 2.        , 2.        , 2.        , 0.33333333,\n",
       "         0.8       ],\n",
       "        [0.        , 2.        , 0.13333333, 0.73333333, 0.26666667,\n",
       "         0.66666667],\n",
       "        [0.        , 2.        , 0.66666667, 0.4       , 0.73333333,\n",
       "         0.13333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         2.        ]]),\n",
       " array([[0.        , 2.        , 2.        , 0.2       , 0.8       ,\n",
       "         0.53333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         2.        ],\n",
       "        [0.        , 2.        , 2.        , 0.86666667, 1.        ,\n",
       "         0.8       ],\n",
       "        [0.        , 2.        , 0.93333333, 0.73333333, 0.13333333,\n",
       "         0.4       ],\n",
       "        [0.        , 0.2       , 0.13333333, 0.86666667, 0.53333333,\n",
       "         0.86666667]]),\n",
       " array([[0.        , 2.        , 2.        , 0.73333333, 0.4       ,\n",
       "         1.        ],\n",
       "        [0.        , 2.        , 0.46666667, 0.53333333, 0.8       ,\n",
       "         0.06666667],\n",
       "        [0.        , 2.        , 2.        , 2.        , 0.66666667,\n",
       "         0.8       ],\n",
       "        [0.        , 0.13333333, 0.8       , 0.4       , 0.53333333,\n",
       "         0.13333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.33333333]]),\n",
       " array([[0.        , 0.73333333, 0.66666667, 0.06666667, 0.73333333,\n",
       "         0.4       ],\n",
       "        [0.        , 2.        , 2.        , 2.        , 0.26666667,\n",
       "         0.4       ],\n",
       "        [0.        , 0.86666667, 0.86666667, 0.6       , 0.06666667,\n",
       "         0.33333333],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.8       ],\n",
       "        [1.        , 2.        , 2.        , 2.        , 0.66666667,\n",
       "         0.4       ]]),\n",
       " array([[1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         1.        ],\n",
       "        [0.        , 2.        , 0.2       , 0.2       , 0.73333333,\n",
       "         0.73333333],\n",
       "        [0.        , 2.        , 1.        , 0.2       , 0.26666667,\n",
       "         0.6       ],\n",
       "        [0.        , 2.        , 2.        , 0.06666667, 0.73333333,\n",
       "         0.4       ],\n",
       "        [1.        , 2.        , 2.        , 1.        , 0.93333333,\n",
       "         0.46666667]]),\n",
       " array([[0.        , 2.        , 0.86666667, 0.93333333, 0.33333333,\n",
       "         1.        ],\n",
       "        [0.        , 0.13333333, 1.        , 1.        , 0.4       ,\n",
       "         0.86666667],\n",
       "        [0.        , 0.06666667, 0.06666667, 0.33333333, 0.33333333,\n",
       "         0.86666667],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         0.8       ],\n",
       "        [1.        , 2.        , 2.        , 2.        , 2.        ,\n",
       "         2.        ]])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 1., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 1., 0.]),\n",
       " array([0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "        0., 0., 0.]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 0.])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
